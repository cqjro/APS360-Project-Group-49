{"cells":[{"cell_type":"markdown","metadata":{"id":"KPc9f0f4BLct"},"source":["# Group 49 Data Processing:\n","This portion will deal with the manipluation of the metadata and images to be suitable for use in our primary model."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"T6_9KSp3HTTX","executionInfo":{"status":"ok","timestamp":1691807789866,"user_tz":240,"elapsed":2,"user":{"displayName":"Cairo Cristante","userId":"00226747864793775746"}}},"outputs":[],"source":["# intial imports\n","import time\n","import pandas as pd\n","import numpy as np\n","from skimage.io import imread\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from torchvision import transforms\n","from torchvision.utils import save_image\n","import matplotlib.image as mpimg\n","import torch"]},{"cell_type":"markdown","metadata":{"id":"sZREesijCuSu"},"source":["## IF USING GOOGLE COLAB\n","\n","Please note that the images will be pulled from the shared folder that this file is stored in, thus it is import that you **CHANGE LINE BELLOW** to the path in which the folder is located on your drive/computer.\n","\n","Relative paths work a little wonky in google colab thus the absolute path is easier to work with."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4T738hcHKd4","outputId":"2957c6cd-8fd2-449a-d9c3-dfe80fff211f","executionInfo":{"status":"ok","timestamp":1691807791703,"user_tz":240,"elapsed":1135,"user":{"displayName":"Cairo Cristante","userId":"00226747864793775746"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive # For when working in Colab for training purposes\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"yriwdeNdDLB1","executionInfo":{"status":"ok","timestamp":1691807791703,"user_tz":240,"elapsed":2,"user":{"displayName":"Cairo Cristante","userId":"00226747864793775746"}}},"outputs":[],"source":["# new data set\n","folder_path = \"/content/drive/MyDrive/APS360 Project /Model\" # no idea if this will work -- Cairo\n","#folder_path = \"/content/drive/MyDrive/APS360/Project /Model\" # -- Kate"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W6QnxCThBRt0","outputId":"114cbcf4-42f7-4601-f5d6-735ad3a9f16a","executionInfo":{"status":"ok","timestamp":1691807926849,"user_tz":240,"elapsed":6,"user":{"displayName":"Cairo Cristante","userId":"00226747864793775746"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Files in Model Directory:\n","[1] Baseline Model\n","[2] Challenge 2019 Images\n","[3] HIBA Images - Test\n","[4] Ham10000\n","[5] __pycache__\n","[6] Saved Models\n","[7] Copy of CNN_primary_model.ipynb\n","[8] Copy of CNN_primary_model - Kate.ipynb\n","[9] CNN_primary_model.ipynb\n","[10] Model Training .gdoc\n","[11] training_data.csv\n","[12] validation_data.csv\n","[13] validation_data_onehot.csv\n","[14] training_data_onehot.csv\n","[15] test_data.csv\n","[16] test_data_onehot.csv\n","[17] Primary Autoencoder.ipynb\n","[18] AnastasiaPlayground.ipynb\n","[19] Copy of Primary_Autoencoder_Cairo.ipynb\n","[20] PROVe-AI\n","[21] Copy of CNN_model - Miranda.ipynb\n","[22] large_training_data.csv\n","[23] large_validation_data.csv\n","[24] large_validation_data_onehot.csv\n","[25] large_training_data_onehot.csv\n","[26] large_test_data.csv\n","[27] large_test_data_onehot.csv\n","[28] MobileNet_Cairo.ipynb\n","[29] utils.py\n","[30] Primary_Autoencoder_Cairo.ipynb\n","[31] MobileNet_Cairo_Metadata_Test.ipynb\n","[32] CNN_model - Miranda.ipynb\n","[33] demo_data_onehot.csv\n","[34] demo_data.csv\n","[35] Presentation_Demonstration.ipynb\n","[36] data_processing.ipynb\n","[37] images.gslides\n"]}],"source":["import os # handling files, file paths and directories\n","\n","# testing the google colab directories\n","directory_files = os.listdir(folder_path) # creates a list of all the files in the directory\n","print('Files in Model Directory:')\n","for i in range(len(directory_files)): # checking all the files in the current directory\n","    if os.path.isdir(directory_files[i]):\n","        image_directory = directory_files[i] # if the file is a directory, it will store the directory in this variable\n","    print(f\"[{i+1}] {directory_files[i]}\")"]},{"cell_type":"markdown","metadata":{"id":"_yssOopRD-Gj"},"source":["## Part 1: Verifying Images\n","\n","When working this this set in the past, sometimes images have been missing despite being listed in the Metadata CSV.\n","\n","Thus, we will doing an inital sanity check to make sure that if an image is listed in the CSV, the image is also present within the folder and vice versa.\n","\n","Additionally, this step will also be used to check that all images within the training set are unique and that none of these images appear in the testing set."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"MN-TzgvjhO0Y","executionInfo":{"status":"ok","timestamp":1691807929631,"user_tz":240,"elapsed":129,"user":{"displayName":"Cairo Cristante","userId":"00226747864793775746"}}},"outputs":[],"source":["categorical_features = ['anatom_site_general', 'benign_malignant', 'diagnosis', 'sex']"]},{"cell_type":"code","source":["def img_transform(folder_path, dataframe, imgs_to_transform, final_amount):\n","  \"\"\"\n","  This function takes in a cleaned dataset and transforms images in classes with less data points to balance the dataset\n","  -- folder_path is the file path only to the metadata csv\n","  -- imgs_to_transform is a list of the classes that need transformed images\n","  -- final amount is the final amount of each the desired classes (single int)\n","  \"\"\"\n","  # load metadata\n","  #metadata_file_path = os.path.join(folder_path, 'metadata.csv')\n","  df_dataset = dataframe\n","  print(f'Initial Number of Images: {len(df_dataset)}')\n","\n","  # get inital class stats\n","  init_class_stats = df_dataset['diagnosis'].value_counts()\n","  print(init_class_stats)\n","\n","  #required_stats = []\n","\n","  #for indx in init_class_stats.iteritems():\n","  #  if indx[0] in imgs_to_transform:\n","  #    required_stats.append(indx)\n","\n","  #print(required_stats)\n","\n","  num_squamous_cell_carcinoma = 0\n","  num_actinic_keratosis = 0\n","  num_dermatofibroma = 0\n","  num_vascular_lesion = 0\n","  num_basal = 0\n","\n","  # dictionary for new data\n","  new_data = {\n","      'isic_id': [],\n","      'age_approx': [],\n","      'anatom_site_general': [],\n","      'benign_malignant': [],\n","      'diagnosis': [],\n","      'sex': []\n","  }\n","\n","  # desired transformations being declared\n","  #transformations  = torch.nn.Sequential(\n","      #transforms.ToPILImage(),\n","      #transforms.RandomRotation(degrees=90),\n","      #transforms.ToTensor())\n","  transformations = transforms.RandomRotation(degrees = 90)\n","  # https://www.projectpro.io/recipes/convert-image-tensor-pytorch\n","  convert_tensor = transforms.ToTensor()\n","\n","  count = 0\n","  # loop through metadata\n","  for i in range(40):\n","    for ind in df_dataset.index:\n","\n","      #id, age, ana_site, b_m, diag\n","      diag = df_dataset['diagnosis'][ind]\n","      if diag in imgs_to_transform:\n","\n","        id = df_dataset['isic_id'][ind]\n","        age = df_dataset['age_approx'][ind]\n","        ana_site = df_dataset['anatom_site_general'][ind]\n","        b_m = df_dataset['benign_malignant'][ind]\n","        sex = df_dataset['sex'][ind]\n","\n","        #print(diag) #testing\n","\n","        img_name = f'Transform{count}'\n","        #print(img_name) #testing\n","        og_img = os.path.join(folder_path, id + '.JPG')\n","\n","        # source: https://discuss.pytorch.org/t/applying-transforms-to-a-single-image/56254\n","        #print(og_img) #testing\n","        image = mpimg.imread(og_img)\n","        new_img = transformations(convert_tensor(image)) # this step rotates the image\n","\n","        new_img_filepath = os.path.join(folder_path, img_name +'.JPG') # this is where the image will be saved\n","        save_image(new_img, new_img_filepath) # should save the image in the declared file type (JPG in this case)\n","\n","        # I had to hard code this next part for the sake of time\n","\n","        count += 1\n","        if diag == 'squamous cell carcinoma' and num_squamous_cell_carcinoma<final_amount:\n","          new_data['isic_id'].append(img_name) # new file name\n","          new_data['age_approx'].append(age)\n","          new_data['anatom_site_general'].append(ana_site)\n","          new_data['benign_malignant'].append(b_m)\n","          new_data['diagnosis'].append(diag)\n","          new_data['sex'].append(sex)\n","          #required_stats[0][1] += 1\n","          num_squamous_cell_carcinoma += 1\n","          #print(diag) #testing\n","\n","        if diag == 'actinic keratosis' and num_actinic_keratosis<final_amount:\n","          new_data['isic_id'].append(img_name)\n","          new_data['age_approx'].append(age)\n","          new_data['anatom_site_general'].append(ana_site)\n","          new_data['benign_malignant'].append(b_m)\n","          new_data['diagnosis'].append(diag)\n","          new_data['sex'].append(sex)\n","          #required_stats[1][1] += 1\n","          num_actinic_keratosis += 1\n","          #print(diag) #testing\n","\n","        if diag == 'dermatofibroma' and num_dermatofibroma<final_amount:\n","          new_data['isic_id'].append(img_name)\n","          new_data['age_approx'].append(age)\n","          new_data['anatom_site_general'].append(ana_site)\n","          new_data['benign_malignant'].append(b_m)\n","          new_data['diagnosis'].append(diag)\n","          new_data['sex'].append(sex)\n","          #required_stats[2][1] += 1\n","          num_dermatofibroma += 1\n","          #print(diag) #testing\n","\n","        if diag == 'vascular lesion' and num_vascular_lesion<final_amount:\n","          new_data['isic_id'].append(img_name)\n","          new_data['age_approx'].append(age)\n","          new_data['anatom_site_general'].append(ana_site)\n","          new_data['benign_malignant'].append(b_m)\n","          new_data['diagnosis'].append(diag)\n","          new_data['sex'].append(sex)\n","          #required_stats[3][1] += 1\n","          num_vascular_lesion += 1\n","          #print(diag) #testing\n","\n","        if diag == 'basal cell carcinoma' and num_basal < final_amount:\n","          new_data['isic_id'].append(img_name)\n","          new_data['age_approx'].append(age)\n","          new_data['anatom_site_general'].append(ana_site)\n","          new_data['benign_malignant'].append(b_m)\n","          new_data['diagnosis'].append(diag)\n","          new_data['sex'].append(sex)\n","          #required_stats[3][1] += 1\n","          num_basal += 1\n","          print(diag) #testing\n","    if num_squamous_cell_carcinoma == final_amount and num_actinic_keratosis == final_amount and num_dermatofibroma == final_amount and num_vascular_lesion == final_amount and num_basal == final_amount: # not sure if that index is done correctly\n","        print(count) #testing\n","        break\n","\n","  # appending the final dictionary to the csv file\n","  # source: https://www.geeksforgeeks.org/how-to-append-pandas-dataframe-to-existing-csv-file/\n","  data_to_add = pd.DataFrame(new_data)\n","  #data_to_add.to_csv(metadata_file_path, mode='a', index=False, header=False)\n","  print(\"Data transformations complete.\")\n","  return data_to_add"],"metadata":{"id":"L7_Y6eBrITlR","executionInfo":{"status":"ok","timestamp":1691807930067,"user_tz":240,"elapsed":134,"user":{"displayName":"Cairo Cristante","userId":"00226747864793775746"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","execution_count":21,"metadata":{"id":"HuTfGwAVYNuk","executionInfo":{"status":"ok","timestamp":1691807933249,"user_tz":240,"elapsed":146,"user":{"displayName":"Cairo Cristante","userId":"00226747864793775746"}}},"outputs":[],"source":["def clean_metadata(dataset_folder_path, train=False):\n","  \"\"\"\n","  This function will take in the dataset folder path as a string a return the clean data as a Panada Data Frame.\n","  \"\"\"\n","  # Load the metadata\n","  dataset_metadata_path = os.path.join(dataset_folder_path, 'metadata.csv')\n","  df = pd.read_csv(dataset_metadata_path)\n","  print(f'Initial Number of Images: {len(df)}')\n","\n","  ################################################################################\n","  # Keep only useful metadata columns\n","  df_dataset = df[['isic_id', 'age_approx', 'anatom_site_general', 'benign_malignant', 'diagnosis', 'sex' ]]\n","\n","  ################################################################################\n","  # Removing any exculded classifications\n","  desired_classifications = ['actinic keratosis', 'basal cell carcinoma', 'dermatofibroma', 'melanoma', 'nevus', 'squamous cell carcinoma', 'vascular lesion']\n","\n","  print(df_dataset['diagnosis'].value_counts)\n","\n","  removed_classifications_indices = []\n","  removed_classifications = set()\n","  len_before_1 = len(df_dataset)\n","  i = 0\n","  nevus_count = 0\n","  melanoma_count = 0\n","  basel_count = 0\n","  for diag in df_dataset['diagnosis']:\n","    if diag not in desired_classifications:\n","      removed_classifications.add(diag)\n","      removed_classifications_indices.append(i)\n","\n","    if train and diag == 'nevus' and nevus_count < 200:\n","      removed_classifications_indices.append(i)\n","      nevus_count += 1\n","    elif train and diag == 'melanoma' and melanoma_count < 0:\n","      removed_classifications_indices.append(i)\n","      melanoma_count += 1\n","    elif train and diag == 'basal cell carcinoma' and basel_count < 0:\n","      removed_classifications_indices.append(i)\n","      basel_count += 1\n","\n","    i += 1\n","  df_dataset = df_dataset.drop(df_dataset.index[removed_classifications_indices])\n","\n","  len_after_1 = len(df_dataset)\n","  num_diagnosis_removed = len_before_1 - len_after_1\n","  print(f'Number of Images removed due to out of scope diagnosis and balancing : {num_diagnosis_removed}')\n","\n","  ################################################################################\n","  # Remove samples with missing metadata\n","  categorical_features = ['anatom_site_general', 'diagnosis', 'sex']\n","  #^ removed benign_malignant in list because it was removing too many images\n","\n","  len_before_2 = len(df_dataset) # report on inital length\n","\n","  missing = pd.concat([df_dataset[c].isnull() for c in categorical_features], axis=1).any(axis=1)\n","  df_dataset = df_dataset[~missing]\n","\n","  len_after_2 = len(df_dataset) # report on length after\n","  num_missing_features = len_before_2 - len_after_2\n","\n","  # Report on image removal\n","  print(f'Number of Images Removed due to Missing Features: {num_missing_features}')\n","  print(f'\\nPercent Removed: {round(((num_missing_features + num_diagnosis_removed)/len_before_1)*100, 2)}%')\n","  print(f'Images remaining: {len(df_dataset)}')\n","\n","  ################################################################################\n","  # Image transformations to balance the dataset\n","  if train == True:\n","\n","    print('image tranformations started')\n","    imgs_to_transform = ['squamous cell carcinoma', 'actinic keratosis', 'dermatofibroma', 'vascular lesion']\n","    final_amount = 100\n","    transformed_data = img_transform(dataset_folder_path, df_dataset, imgs_to_transform, final_amount)\n","\n","    # merging dataframes\n","    df_dataset = pd.concat([df_dataset, transformed_data], ignore_index=True)\n","    print('\\ndataframes merged')\n","\n","  ################################################################################\n","  # Class Statistics:\n","  print('\\nLabel Breakdown: ')\n","  print(df_dataset['diagnosis'].value_counts())\n","  print(f\"\\n{df_dataset['benign_malignant'].value_counts()}\")\n","\n","  ################################################################################\n","  # One-Hot Encoding of Data\n","  dataset_onehot = pd.get_dummies(df_dataset[['age_approx','anatom_site_general', 'sex', 'benign_malignant', 'diagnosis']])\n","  dataset_onehot.insert(loc=0, column='isic_id', value=df_dataset['isic_id'])\n","\n","  ################################################################################\n","  # Normlaize Age Column in onehot encoding data\n","  col = 'age_approx'\n","  dataset_onehot[col] = (dataset_onehot[col] - dataset_onehot[col].min()) / (dataset_onehot[col].max() - dataset_onehot[col].min())\n","\n","  ################################################################################\n","  return dataset_onehot, df_dataset,"]},{"cell_type":"code","source":["def print_stats(folder_path):\n","\n","  #metadata_file_path = os.path.join(folder_path, 'metadata.csv')\n","  df_dataset = pd.read_csv(folder_path)\n","\n","  print('\\nLabel Breakdown: ')\n","  print(df_dataset['diagnosis'].value_counts())\n","  print(f\"\\n{df_dataset['benign_malignant'].value_counts()}\")"],"metadata":{"id":"UYhBJwg2eEq3","executionInfo":{"status":"ok","timestamp":1691807937403,"user_tz":240,"elapsed":3,"user":{"displayName":"Cairo Cristante","userId":"00226747864793775746"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aHrogCTbEq9C"},"outputs":[],"source":["# Establishing Directories based on the input\n","train_images_path = os.path.join(folder_path, 'Ham10000')\n","test_images_path = os.path.join(folder_path, 'HIBA Images - Test')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKlTpqV8P3h9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691704248735,"user_tz":240,"elapsed":116380,"user":{"displayName":"Cairo Cristante","userId":"00226747864793775746"}},"outputId":"a91e1e9f-d671-4416-d0a8-55bc90d34c91"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initial Number of Images: 11720\n","Number of Images removed due to out of scope diagnosis and balancing : 9155\n","Number of Images Removed due to Missing Features: 435\n","\n","Percent Removed: 81.83%\n","Images remaining: 2130\n","image tranformations started\n","Initial Number of Images: 11720\n","nevus                         7737\n","pigmented benign keratosis    1338\n","melanoma                      1305\n","basal cell carcinoma           622\n","squamous cell carcinoma        229\n","vascular lesion                180\n","dermatofibroma                 160\n","actinic keratosis              149\n","Name: diagnosis, dtype: int64\n","Data transformations complete.\n","\n","dataframes merged\n","\n","Label Breakdown: \n","nevus                      506\n","basal cell carcinoma       501\n","dermatofibroma             500\n","squamous cell carcinoma    500\n","vascular lesion            500\n","actinic keratosis          500\n","melanoma                   494\n","Name: diagnosis, dtype: int64\n","\n","benign       506\n","malignant    494\n","Name: benign_malignant, dtype: int64\n"]}],"source":["# Run Cleaning Function\n","train_onehot, train_data = clean_metadata(train_images_path, train=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1fT8ez8V7Aar","outputId":"2fe69b27-dd89-4994-a9b8-a72b949fbee3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691704248736,"user_tz":240,"elapsed":7,"user":{"displayName":"Cairo Cristante","userId":"00226747864793775746"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Initial Number of Images: 1635\n","Number of Images removed due to out of scope diagnosis and balancing : 88\n","Number of Images Removed due to Missing Features: 114\n","\n","Percent Removed: 12.35%\n","Images remaining: 1433\n","\n","Label Breakdown: \n","nevus                      532\n","basal cell carcinoma       322\n","melanoma                   255\n","squamous cell carcinoma    157\n","actinic keratosis           63\n","dermatofibroma              61\n","vascular lesion             43\n","Name: diagnosis, dtype: int64\n","\n","malignant    734\n","benign       699\n","Name: benign_malignant, dtype: int64\n"]}],"source":["test_onehot, test_data = clean_metadata(test_images_path)"]},{"cell_type":"code","source":["test_onehot_keep, test_onehot_drop, test_data_keep, test_data_drop = train_test_split(test_onehot, test_data, test_size=0.65, random_state=0)"],"metadata":{"id":"INf6ng-Yphxj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data_keep['diagnosis'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZAEZpHeqBUX","executionInfo":{"status":"ok","timestamp":1691704298070,"user_tz":240,"elapsed":3,"user":{"displayName":"Cairo Cristante","userId":"00226747864793775746"}},"outputId":"b50b0929-3d5c-4e49-c072-7c16b9f0a567"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["nevus                      215\n","basal cell carcinoma       132\n","melanoma                   106\n","squamous cell carcinoma     55\n","actinic keratosis           28\n","dermatofibroma              21\n","vascular lesion             16\n","Name: diagnosis, dtype: int64"]},"metadata":{},"execution_count":117}]},{"cell_type":"code","source":["train_data, validation_data, train_onehot, validation_onehot = train_test_split(train_data, train_onehot, test_size=0.17, random_state=0)"],"metadata":{"id":"3OQDkxAFuaTe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_data = len(train_data) + len(validation_data) + len(test_data_keep)\n","print(f'Total Number of Images {total_data}')\n","\n","print(f'\\nLength of Train Data: {len(train_data)}')\n","print(f'Length of Train Data Onehot: {len(train_onehot)}')\n","print(f'Percent of Total: {round(len(train_data)/total_data*100, 2)}%')\n","\n","print(f'\\nLength of Validation Data: {len(validation_data)}')\n","print(f'Length of Validation Data Onehot: {len(validation_onehot)}')\n","print(f'Percent of Total: {round(len(validation_data)/total_data*100, 2)}%')\n","\n","print(f'\\nLength of Test Data: {len(test_data_keep)}')\n","print(f'Length of Test Data Onehot: {len(test_onehot_keep)}')\n","print(f'Percent of Total: {round(len(test_data_keep)/total_data*100, 2)}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vo_3U6SIWbf_","executionInfo":{"status":"ok","timestamp":1691704314767,"user_tz":240,"elapsed":135,"user":{"displayName":"Cairo Cristante","userId":"00226747864793775746"}},"outputId":"35db3235-85a8-4bf2-853d-275e08b49023"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Number of Images 3406\n","\n","Length of Train Data: 2411\n","Length of Train Data Onehot: 2411\n","Percent of Total: 70.79%\n","\n","Length of Validation Data: 494\n","Length of Validation Data Onehot: 494\n","Percent of Total: 14.5%\n","\n","Length of Test Data: 501\n","Length of Test Data Onehot: 501\n","Percent of Total: 14.71%\n"]}]},{"cell_type":"code","source":["train_data.to_csv(os.path.join(folder_path, 'large_training_data.csv'))\n","train_onehot.to_csv(os.path.join(folder_path, 'large_training_data_onehot.csv'))\n","\n","validation_data.to_csv(os.path.join(folder_path, 'large_validation_data.csv'))\n","validation_onehot.to_csv(os.path.join(folder_path, 'large_validation_data_onehot.csv'))\n","\n","test_data_keep.to_csv(os.path.join(folder_path, 'large_test_data.csv'))\n","test_onehot_keep.to_csv(os.path.join(folder_path, 'large_test_data_onehot.csv'))"],"metadata":{"id":"MmJwCMxeMfZV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["demo_onehot, demo_data = clean_metadata(os.path.join(folder_path, 'PROVe-AI'), True)\n","demo_onehot.to_csv(os.path.join(folder_path, 'demo_data_onehot.csv'))\n","demo_data.to_csv(os.path.join(folder_path, 'demo_data.csv'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":825},"id":"VcmMEexicHiv","executionInfo":{"status":"error","timestamp":1691809527158,"user_tz":240,"elapsed":1578954,"user":{"displayName":"Cairo Cristante","userId":"00226747864793775746"}},"outputId":"4c5da014-1ba7-4f24-8148-97d85dd4f620"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial Number of Images: 603\n","<bound method IndexOpsMixin.value_counts of 0         seborrheic keratosis\n","1                        nevus\n","2      squamous cell carcinoma\n","3                     melanoma\n","4      squamous cell carcinoma\n","                ...           \n","598       seborrheic keratosis\n","599             dermatofibroma\n","600        lichenoid keratosis\n","601                lentigo NOS\n","602                   melanoma\n","Name: diagnosis, Length: 603, dtype: object>\n","Number of Images removed due to out of scope diagnosis and balancing : 344\n","Number of Images Removed due to Missing Features: 0\n","\n","Percent Removed: 57.05%\n","Images remaining: 259\n","image tranformations started\n","Initial Number of Images: 259\n","nevus                      112\n","melanoma                    95\n","actinic keratosis           19\n","squamous cell carcinoma     13\n","dermatofibroma              11\n","basal cell carcinoma         9\n","Name: diagnosis, dtype: int64\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-f420574e4ad4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdemo_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemo_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PROVe-AI'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdemo_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'demo_data_onehot.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdemo_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'demo_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-0122eadcf957>\u001b[0m in \u001b[0;36mclean_metadata\u001b[0;34m(dataset_folder_path, train)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mimgs_to_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'squamous cell carcinoma'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'actinic keratosis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dermatofibroma'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vascular lesion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mfinal_amount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mtransformed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs_to_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_amount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# merging dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-c7fd4838064e>\u001b[0m in \u001b[0;36mimg_transform\u001b[0;34m(folder_path, dataframe, imgs_to_transform, final_amount)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mnew_img_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.JPG'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this is where the image will be saved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_img_filepath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# should save the image in the declared file type (JPG in this case)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# I had to hard code this next part for the sake of time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/utils.py\u001b[0m in \u001b[0;36msave_image\u001b[0;34m(tensor, fp, format, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# Add 0.5 after unnormalizing to [0, 255] to round to the nearest integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mndarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tobytes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3099\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3101\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}